{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa761a71",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c74cb",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "\n",
    "- **`Description`**  \n",
    "  The Data Set was downloaded from Kaggle, from the following [link](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).\n",
    "\n",
    "- **`Context`**  \n",
    "  In real estate, a home's price is influenced by far more than just its size or number of rooms.  \n",
    "  This dataset includes 81 detailed features of homes allowing a rich ground for exploring what really drives house prices.  \n",
    "  It reveals how hidden patterns in data can explain price differences in homes.\n",
    "\n",
    "- **`Content`**  \n",
    "    This dataset contains 1,460 rows and 81 columns, with detailed information on residential properties in Ames, Iowa.  \n",
    "  Features range from lot size, zoning, and neighborhood to quality ratings, year built, and sale conditions including the target variable, `SalePrice`.\n",
    "\n",
    "- **`Acknowledgements`**  \n",
    "    The dataset is part of a Kaggle competition and is built on the Ames Housing dataset by Dean De Cock.\n",
    "     \n",
    "- **`Inspiration`**  \n",
    "  This dataset allows to explore what makes one home more valuable than another and how different features affect home prices. The insights can help people make smart choices in buying, selling, or investing in homes and support better decisions in the real estate market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45827b",
   "metadata": {},
   "source": [
    "# Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9551c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bed418",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86368c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path.cwd().resolve()\n",
    "ROOT_DIR = current_path.parents[0]  # Get the parent directory of the current path\n",
    "print(f\"Root directory: {ROOT_DIR}\")\n",
    "\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "TEST_DIR = ROOT_DIR / 'test'\n",
    "print(f\"Test directory: {TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d06420",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(DATA_DIR / 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810ee44",
   "metadata": {},
   "source": [
    "## Description of the shape and type of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show shape of the dataset\n",
    "print(f\"Shape of the dataset: {training_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f93bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the columns of the dataset\n",
    "print(f\"Columns of the dataset: {training_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows of the dataset\n",
    "print(f\"First few rows of the dataset: \")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150015d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the description of the dataset\n",
    "print(f\"Description of the dataset: \")\n",
    "training_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfae713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Id column\n",
    "training_data = training_data.drop(columns=['Id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be98cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information about the dataset\n",
    "print(f\"Information about the dataset: \")\n",
    "training_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique values for object columns\n",
    "object_df = training_data.select_dtypes(include='object')\n",
    "object_cols = object_df.columns.unique().to_list()\n",
    "print(f\"Lenght of object columns: {len(object_cols)}\")\n",
    "print(f\"Object columns and their unique values:\")\n",
    "object_df.nunique().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b86d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select unique values for non-object columns\n",
    "non_object_df = training_data.select_dtypes(exclude='object')\n",
    "non_object_cols = non_object_df.columns.unique().to_list()\n",
    "print(f\"Lenght of non-object columns: {len(non_object_cols)}\")\n",
    "print(f\"Non-object columns and their unique values:\")\n",
    "non_object_df.nunique().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5832b61",
   "metadata": {},
   "source": [
    "# Deal with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40502dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values(df):\n",
    "    # Draw a heatmap using missing values\n",
    "    missing_value = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_value = missing_value[missing_value > 0]  # Filter out columns with no missing values\n",
    "    if missing_value.empty:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "        return None, None\n",
    "    missing_value = missing_value.reset_index()\n",
    "\n",
    "    # Create a bar chart using plotly\n",
    "    fig_missing = px.bar(\n",
    "        missing_value,  # Reshape to 2D array for heatmap\n",
    "        labels={'index': 'Feature', '0': 'Missing Values'},\n",
    "        x=missing_value['index'],\n",
    "        y=missing_value[0],\n",
    "        color_continuous_scale='Blues',\n",
    "    ).update_layout(\n",
    "        title='Missing Values Bar Chart',\n",
    "        xaxis=dict(tickangle=-45),      # Rotate x-axis labels \n",
    "    ).show()\n",
    "\n",
    "    return missing_value, fig_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116deac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values_percentage(df):\n",
    "    # Calculate the percentage of missing values in each column\n",
    "    missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_values = missing_values[missing_values > 0]  # Filter out columns with no missing values\n",
    "    if missing_values.empty:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "        return None, None\n",
    "    missing_values_percentage = missing_values / len(df) * 100\n",
    "\n",
    "    # Create a bar chart using plotly\n",
    "    fig_missing_percentage = px.bar(\n",
    "        missing_values_percentage,  # Filter out columns with no missing values\n",
    "        labels={'index': 'Feature', 'value': 'Missing Values Percentage'},\n",
    "        x=missing_values_percentage.index,\n",
    "        y=missing_values_percentage.values,\n",
    "        color_continuous_scale='Blues',\n",
    "    ).update_layout(\n",
    "        title='Missing Values Percentage Bar Chart',\n",
    "        xaxis=dict(tickangle=-45),      # Rotate x-axis labels \n",
    "    ).show()\n",
    "\n",
    "    return missing_values_percentage, fig_missing_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28daae4e",
   "metadata": {},
   "source": [
    "## Categorial columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values(object_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values_percentage(object_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Alley', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "training_data = training_data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63a3ed",
   "metadata": {},
   "source": [
    "### 1. MasVnrType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d25613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sum of missing values of MasVnrType\n",
    "mas_vnr_type_missing = training_data['MasVnrType'].isnull().sum()\n",
    "print(f\"Missing values in MasVnrType: {mas_vnr_type_missing}\")\n",
    "\n",
    "# Show the unique values of MasVnrType\n",
    "mas_vnr_type_unique = training_data['MasVnrType'].unique()\n",
    "print(f\"Unique values in MasVnrType: {mas_vnr_type_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the MasVnrType column has a lot of missing values\n",
    "# The value nan of MasVnrType column likely represents houses\n",
    "# without masonry veneer, so we can fill it with 'None'\n",
    "training_data['MasVnrType'] = training_data['MasVnrType'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b01a8",
   "metadata": {},
   "source": [
    "### 2. FirePlaceQu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sum of missing values of FirePlaceQu\n",
    "fireplace_qu_missing = training_data['FireplaceQu'].isnull().sum()\n",
    "print(f\"Missing values in FirePlaceQu: {fireplace_qu_missing}\")\n",
    "\n",
    "# Show the unique values of FirePlaceQu\n",
    "fireplace_qu_unique = training_data['FireplaceQu'].unique()\n",
    "print(f\"Unique values in FirePlaceQu: {fireplace_qu_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce853103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the FirePlaceQu column has a lot of missing values\n",
    "# The value nan of FirePlaceQu column represents fire place in houses \n",
    "# So we can fill it with 'None'\n",
    "training_data['FireplaceQu'] = training_data['FireplaceQu'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54aecdc",
   "metadata": {},
   "source": [
    "### 3. Garage: GarageType, GarageCond, GarageQual, GarageFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GarageType, GarageCond, GarageQual, GarageFinish columns have a some missing values\n",
    "# We can fill them with 'None' because they represent houses without garage\n",
    "garage_cols = ['GarageType', 'GarageCond', 'GarageQual', 'GarageFinish']\n",
    "for col in garage_cols:\n",
    "    training_data[col] = training_data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b4c82",
   "metadata": {},
   "source": [
    "### 4. Basement:  BsmtFinType2, BsmtExposure, BsmtFinType1, BsmtQual, BsmtCond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c496ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basement columns have a some missing values\n",
    "# We can fill them with 'None' because they represent houses without basement\n",
    "basement_cols = ['BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtQual', 'BsmtCond']\n",
    "for col in basement_cols:\n",
    "    training_data[col] = training_data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796eb5f",
   "metadata": {},
   "source": [
    "### 5. Electrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43033d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the missing values of Electrical\n",
    "electrical_missing = training_data['Electrical'].isnull().sum()\n",
    "print(f\"Missing values in Electrical: {electrical_missing}\")    \n",
    "\n",
    "# Show the unique values of Electrical\n",
    "electrical_unique = training_data['Electrical'].unique()\n",
    "print(f\"Unique values in Electrical: {electrical_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a12e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Electrical column has a just one missing value\n",
    "# We can fill it with the most common value in the column\n",
    "most_common_electrical = training_data['Electrical'].mode()[0]\n",
    "print(f\"Most common value in Electrical: {most_common_electrical}\")\n",
    "\n",
    "# Fill the missing value in Electrical with the most common value\n",
    "training_data['Electrical'] = training_data['Electrical'].fillna(most_common_electrical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab1627",
   "metadata": {},
   "source": [
    "### Check the missing value of object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that have been removed from object_cols\n",
    "for i in cols_to_drop:\n",
    "    try:\n",
    "        object_cols.remove(i)\n",
    "    except ValueError:\n",
    "        print(f\"Column {i} not found in object_cols, skipping removal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6de312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing value of object columns\n",
    "object_df = training_data.select_dtypes(include='object')[object_cols]\n",
    "plot_missing_values(object_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607899a8",
   "metadata": {},
   "source": [
    "## Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ea690",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values(non_object_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa84511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values_percentage(non_object_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8bfdb",
   "metadata": {},
   "source": [
    "### 1. LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sum of missing values in LotFrontage\n",
    "lot_frontage_missing = training_data['LotFrontage'].isnull().sum()\n",
    "print(f\"Sum of missing values in LotFrontage: {lot_frontage_missing}\")\n",
    "\n",
    "# Check the unique values in LotFrontage\n",
    "unique_lot_frontage = training_data['LotFrontage'].unique()\n",
    "print(f\"Unique values in LotFrontage: {unique_lot_frontage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402dfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the violin plot for LotFrontage\n",
    "px.violin(training_data, y='LotFrontage', box=True, points='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50275c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LotFrontage column has some outliers and missing values.\n",
    "# We can filled the missing values in LotFrontage with the mean value\n",
    "mean_lot_frontage = training_data['LotFrontage'].mean()\n",
    "# Fill the missing values in LotFrontage with the mean value\n",
    "training_data['LotFrontage'] = training_data['LotFrontage'].fillna(mean_lot_frontage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e5168",
   "metadata": {},
   "source": [
    "### 2. GarageYrBlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c55029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of nan value of GarageType\n",
    "index_nan_GarageType = training_data[training_data['GarageType'] == 'None'].index\n",
    "\n",
    "# Get index of nan value of GaraYrBlt\n",
    "index_nan_GaraYrBlt = training_data[training_data['GarageYrBlt'].isna()].index\n",
    "\n",
    "# Compare index of 2 features\n",
    "index_nan_GarageType == index_nan_GaraYrBlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the nan index of GarageType and GaraYrBlt is same\n",
    "# So we can't use median or mean value to fill in the nan value (These homes \n",
    "# don't have a garage)\n",
    "training_data['GarageYrBlt'] = training_data['GarageYrBlt'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45c319",
   "metadata": {},
   "source": [
    "### 3. MasVnrArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f738c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check how many rows have missing values (NaN) in 'MasVnrArea'\n",
    "print(\"Number of rows with MasVnrArea as NaN:\", training_data[training_data['MasVnrArea'].isnull()].shape[0])  # Output: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Display details of these rows to inspect their 'MasVnrType'\n",
    "print(\"\\nDetails of rows where MasVnrArea is NaN:\")\n",
    "display(training_data[training_data['MasVnrArea'].isnull()][['MasVnrType', 'MasVnrArea']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Count how many houses have no masonry veneer (MasVnrType == 'None')\n",
    "print(f\"\\nNumber of houses with MasVnrType = 'None': {training_data[training_data['MasVnrType'] == 'None'].shape[0]}\")  # Output: 872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Find inconsistent rows: MasVnrType is 'None' but MasVnrArea is not zero\n",
    "# # This violates logical consistency — if there's no veneer, area should be 0\n",
    "inconsistent_rows = training_data[(training_data['MasVnrType'] == 'None') & (training_data['MasVnrArea'] != 0)]\n",
    "print(f\"\\nNumber of inconsistent rows (MasVnrType='None' but MasVnrArea ≠ 0): {len(inconsistent_rows)}\")\n",
    "inconsistent_rows[['MasVnrType', 'MasVnrArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46217eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Check consistent rows: MasVnrType is 'None' and MasVnrArea is 0\n",
    "# # These are logically correct\n",
    "consistent_rows = training_data[(training_data['MasVnrType'] == 'None') & (training_data['MasVnrArea'] == 0)]\n",
    "print(f\"Number of consistent rows (MasVnrType='None' and MasVnrArea = 0): {len(consistent_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. FIX INCONSISTENCY: Set MasVnrArea = 0 where MasVnrType is 'None' but area is non-zero\n",
    "# # Logical rule: No veneer → area must be zero\n",
    "training_data.loc[(training_data['MasVnrType'] == 'None') & (training_data['MasVnrArea'] != 0), 'MasVnrArea'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b79da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. HANDLE MISSING VALUES in MasVnrArea\n",
    "# We now handle the 8 NaNs in MasVnrArea based on MasVnrType:\n",
    "# - If MasVnrType is 'None', then MasVnrArea should be 0\n",
    "# - Otherwise, impute using group mean (by MasVnrType) for better accuracy\n",
    "\n",
    "# Step 1: Fill MasVnrArea = 0 if MasVnrType is 'None' and MasVnrArea is NaN\n",
    "training_data.loc[(training_data['MasVnrType'] == 'None') & (training_data['MasVnrArea'].isnull()), 'MasVnrArea'] = 0\n",
    "\n",
    "# Step 2: For remaining NaNs, fill with the average MasVnrArea within the same MasVnrType group\n",
    "# This preserves patterns — e.g., 'BrkFace' homes will use average BrkFace area\n",
    "training_data['MasVnrArea'] = training_data.groupby('MasVnrType')['MasVnrArea'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# # Step 3: If any NaNs still remain (e.g., a group had all NaNs), fill with overall mean\n",
    "if training_data['MasVnrArea'].isnull().any():\n",
    "    training_data['MasVnrArea'] = training_data['MasVnrArea'].fillna(training_data['MasVnrArea'].mean())\n",
    "\n",
    "# Step 4 Final validation: Ensure no inconsistencies remain\n",
    "# Double-check that no house has 'None' veneer type but non-zero area\n",
    "final_check = training_data[(training_data['MasVnrType'] == 'None') & (training_data['MasVnrArea'] != 0)]\n",
    "print(f\"Length of final check: {final_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd52468",
   "metadata": {},
   "source": [
    "# Descriptive Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660af09f",
   "metadata": {},
   "source": [
    "Although `MSSubClass` represents **categorical codes for types of dwellings** involved in the sale. Description in 'data_description.txt':\n",
    "\n",
    "    20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "    30\t1-STORY 1945 & OLDER\n",
    "    40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "    45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "    50\t1-1/2 STORY FINISHED ALL AGES\n",
    "    60\t2-STORY 1946 & NEWER\n",
    "    70\t2-STORY 1945 & OLDER\n",
    "    75\t2-1/2 STORY ALL AGES\n",
    "    80\tSPLIT OR MULTI-LEVEL\n",
    "    85\tSPLIT FOYER\n",
    "    90\tDUPLEX - ALL STYLES AND AGES\n",
    "    120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "    150\t1-1/2 STORY PUD - ALL AGES\n",
    "    160\t2-STORY PUD - 1946 & NEWER\n",
    "    180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "    190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "\n",
    "-> we will convert it to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['MSSubClass'] = training_data['MSSubClass'].astype('object')\n",
    "object_cols = training_data.select_dtypes(include= 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'MSSubClass' in object_cols.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbbaa7",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplot gird for all numerical features\n",
    "rows = (len(non_object_df.columns) + 3) // 4\n",
    "fig = sp.make_subplots(\n",
    "    rows= rows,\n",
    "    cols= 4,\n",
    "    subplot_titles= non_object_df.columns\n",
    ") \n",
    "\n",
    "for i, col in enumerate(non_object_df.columns):\n",
    "    row = i // 4 + 1\n",
    "    col_pos = i % 4 + 1\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x= non_object_df[col], name= col),\n",
    "        row= row, col= col_pos\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Histograms for Numerical Columns\",\n",
    "    height=300*rows,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d63468",
   "metadata": {},
   "source": [
    "- Most features like house area and garage size have small values for most homes, but a few are very big.\n",
    "\n",
    "- Features like number of bathrooms, garages, and fireplaces have specific counts, mostly 1, 2, or 3.\n",
    "\n",
    "- Year-related features show that more houses were built or remodeled in recent years.\n",
    "\n",
    "- Some features like LotArea, PoolArea, and MiscVal have a few very high values.\n",
    "\n",
    "- The house price (SalePrice) is also higher for a few homes, but most are mid-range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98fade",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for non-object columns\n",
    "coor_matrix = training_data[non_object_cols].corr()\n",
    "coor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the heatmap using plotly\n",
    "# Note: Plotly does not have a direct equivalent of seaborn's heatmap, but we can use px.imshow to create a similar effect\n",
    "fig = px.imshow(\n",
    "    coor_matrix,\n",
    "    text_auto='.2f',                # Display correlation values with 2 decimal places\n",
    "    color_continuous_scale='RdBu_r', # Set color scale\n",
    "    aspect='auto',               # Adjust aspect ratio\n",
    "    labels=dict(color=\"Correlation\")\n",
    ")\n",
    "\n",
    "# Configure the layout of the heatmap\n",
    "fig.update_layout(\n",
    "    title='Correlation Heatmap',\n",
    "    width=1200,\n",
    "    height=1200,\n",
    "    xaxis=dict(tickangle=-45),      # Rotate x-axis labels \n",
    "    yaxis=dict(tickangle=0)\n",
    ")\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc01e07",
   "metadata": {},
   "source": [
    "Skewness describes the shape of a distribution and tells us if the data is symmetrical or not.\n",
    "\n",
    "Skewness = 0 → symmetrical \n",
    "\n",
    "Skewness > 0 → right (positive) skew \n",
    "\n",
    "Skewness < 0 → left (negative) skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the skweness of the dataset\n",
    "skewness = training_data[non_object_cols].skew().sort_values(ascending=False)\n",
    "print(f\"Skewness of the dataset: {skewness}\")\n",
    "print('\\n')\n",
    "print(f\"5 highest skewness values: \\n{skewness.head(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b240a7a",
   "metadata": {},
   "source": [
    "Kurtosis ≈ 0: The distribution has a sharpness similar to the normal distribution (called mesokurtic).\n",
    "\n",
    "Kurtosis > 0: The distribution is more peaked than normal, with a higher peak and heavier tails (leptokurtic).\n",
    "\n",
    "→ Data is highly concentrated around the mean, but has more extreme values (outliers) in the tails.\n",
    "\n",
    "Kurtosis < 0: The distribution is flatter than normal, with a lower peak and thinner tails (platykurtic).\n",
    "\n",
    "→ Data is more evenly spread out and less concentrated around the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136082f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the kurtosis of the dataset\n",
    "kurtosis = training_data[non_object_cols].kurtosis().sort_values(ascending=False)\n",
    "print(f\"Kurtosis of the dataset: {kurtosis}\")\n",
    "print('\\n')\n",
    "print(f\"5 highest kurtosis values: \\n{kurtosis.head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 highest correlated features with SalePrice\n",
    "list_highest_coor = list(coor_matrix['SalePrice'].abs().sort_values(ascending=False).head(10).to_dict())\n",
    "print(f\"10 highest correlated features with SalePrice: {list_highest_coor}\")\n",
    "\n",
    "# Get coorrelation matrix for the highest correlated features\n",
    "coor_matrix_highest = training_data[list_highest_coor].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aca407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the heatmap using plotly\n",
    "# Note: Plotly does not have a direct equivalent of seaborn's heatmap, but we can use px.imshow to create a similar effect\n",
    "fig = px.imshow(\n",
    "    coor_matrix_highest,\n",
    "    text_auto='.2f',                # Display correlation values with 2 decimal places\n",
    "    color_continuous_scale='RdBu_r', # Set color scale\n",
    "    aspect='auto',               # Adjust aspect ratio\n",
    "    labels=dict(color=\"Correlation\")\n",
    ")\n",
    "\n",
    "# Configure the layout of the heatmap\n",
    "fig.update_layout(\n",
    "    title='Correlation Heatmap',\n",
    "    width=800,\n",
    "    height=800,\n",
    "    xaxis=dict(tickangle=-45),      # Rotate x-axis labels \n",
    "    yaxis=dict(tickangle=0)\n",
    ")\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a38d67",
   "metadata": {},
   "source": [
    "Top Features Most Correlated with SalePrice\n",
    "\n",
    "OverallQual → 0.79: The strongest correlated feature with sale price, reflecting the overall quality of materials and finish of the house.\n",
    "\n",
    "GrLivArea → 0.71: Above-ground living area; larger homes typically sell for higher prices.\n",
    "\n",
    "GarageCars → 0.64: Number of cars that can fit in the garage; more garage spaces generally increase the home’s value.\n",
    "\n",
    "GarageArea → 0.62: Total garage area (sq ft); larger garages are usually associated with higher sale prices.\n",
    "\n",
    "TotalBsmtSF → 0.61: Total basement area; bigger basements tend to increase the selling price.\n",
    "\n",
    "1stFlrSF → 0.61: First floor square footage; a larger first floor is linked to higher home values.\n",
    "\n",
    "FullBath → 0.56: Number of full bathrooms; more full bathrooms typically result in a higher sale price.\n",
    "\n",
    "TotRmsAbvGrd → 0.53: Total number of rooms above ground; more rooms generally correlate with a higher selling price.\n",
    "\n",
    "YearBuilt → 0.52: Year the house was built; newer houses tend to sell for higher prices.\n",
    "\n",
    "Note: Several features are highly correlated with each other, which can lead to multicollinearity. Examples include: GarageCars & GarageArea or TotalBsmtSF & 1stFlrSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e79d0",
   "metadata": {},
   "source": [
    "## Top 10 Features Most Correlated with SalePrice|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974e71d",
   "metadata": {},
   "source": [
    "### OverallQual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802d90c",
   "metadata": {},
   "source": [
    "-> `OverallQual` has the **strongest correlation** with `SalePrice` at **0.79**.\n",
    "- As the quality rating increases, the house price also increases.\n",
    "- It shows the overall material and finish quality, with values from **1 (Very Poor)** to **10 (Excellent)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for OverallQual\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'OverallQual',\n",
    "    y = 'SalePrice', \n",
    "    title= 'Sale price distribution by overall quality',\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e305779",
   "metadata": {},
   "source": [
    "### GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for GrLivArea\n",
    "px.scatter(\n",
    "    data_frame= training_data, \n",
    "    x = 'GrLivArea',\n",
    "    y = 'SalePrice', \n",
    "    color= 'OverallQual',\n",
    "    title= 'Sale price distribution by overall quality',\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036fbc9",
   "metadata": {},
   "source": [
    "There are some point in the ground living area more than 4000 square feet with overall quality 10 is cost\n",
    "\n",
    "less than 400k $. Such points are outliers. So we must remove these points. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baeaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_mask = (training_data['GrLivArea'] > 4000) & (training_data['SalePrice'] < 200000) & (training_data['OverallQual'] == 10)\n",
    "training_data = training_data[~outlier_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c66f9",
   "metadata": {},
   "source": [
    "### GarageCars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for GarageCars\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'GarageCars',\n",
    "    y = 'SalePrice', \n",
    "    title= 'Sale price distribution by garage car',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33e935",
   "metadata": {},
   "source": [
    "Sale price increase with garage size, and there are some outliers for 3-cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d7348",
   "metadata": {},
   "source": [
    "### GarageArea \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3593e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for GarageCars\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'GarageArea',\n",
    "    title= 'Box plot garage area',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bcf4c",
   "metadata": {},
   "source": [
    "The common areas in range [330, 570] square feet\n",
    "\n",
    "Have outliers on the garage areas greater than ~950 square ft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646f14b",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of garage areas\n",
    "px.histogram(\n",
    "    data_frame= training_data,\n",
    "    x = 'GarageArea',\n",
    "    title= 'Distribution garage areas',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2ae5e",
   "metadata": {},
   "source": [
    "Distribution of garage area is right positively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "px.scatter(\n",
    "    data_frame= training_data,\n",
    "    x = 'GarageArea',\n",
    "    y = 'SalePrice',\n",
    "    color= 'OverallQual'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271a6dd",
   "metadata": {},
   "source": [
    "As the garage area increases, the sale price generally tends to increase as well.\n",
    "\n",
    "The relationship is not perfectly linear, at larger garage areas there is spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b746ad",
   "metadata": {},
   "source": [
    "### TotalBsmtSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for TotalBsmtSF\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'TotalBsmtSF',\n",
    "    title= 'Box plot TotalBsmtSF',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f738e",
   "metadata": {},
   "source": [
    "The common total square feet of basement area in range [330, 570] square feet\n",
    "\n",
    "Have outliers on the garage areas greater than ~2050 square ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of TotalBsmtSF\n",
    "px.histogram(\n",
    "    data_frame= training_data,\n",
    "    x = 'TotalBsmtSF',\n",
    "    title= 'Distribution total square feet of basement area',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf1fa2",
   "metadata": {},
   "source": [
    "Total basement area distribution is right-skewed (positively skewed).\n",
    "\n",
    "Most homes have a basement area between 800 and 1800 square feet, with a peak around 1000 square feet.\n",
    "\n",
    "There are a little homes with very large basement areas (greater than 3000 sq ft).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "px.scatter(\n",
    "    data_frame= training_data,\n",
    "    x = 'TotalBsmtSF',\n",
    "    y = 'SalePrice',\n",
    "    color= 'OverallQual'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a770b5",
   "metadata": {},
   "source": [
    "### 1stFlrSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for 1stFlrSF\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = '1stFlrSF',\n",
    "    title= 'Box plot 1stFlrSF',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 1stFlrSF\n",
    "px.histogram(\n",
    "    data_frame= training_data,\n",
    "    x = '1stFlrSF',\n",
    "    title= 'Distribution first floor square feet',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01489ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "px.scatter(\n",
    "    data_frame= training_data,\n",
    "    x = '1stFlrSF',\n",
    "    y = 'SalePrice',\n",
    "    color= 'OverallQual'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7173233",
   "metadata": {},
   "source": [
    "### FullBath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for FullBath\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'FullBath',\n",
    "    title= 'Box plot FullBath',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afad312",
   "metadata": {},
   "source": [
    "Full Bath has no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 1stFlrSF\n",
    "px.histogram(\n",
    "    data_frame= training_data,\n",
    "    x = 'FullBath',\n",
    "    title= 'Distribution of full bathrooms above grade',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "px.scatter(\n",
    "    data_frame= training_data,\n",
    "    x = 'FullBath',\n",
    "    y = 'SalePrice',\n",
    "    color= 'OverallQual'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ae58e",
   "metadata": {},
   "source": [
    "### YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for FullBath\n",
    "px.box(\n",
    "    data_frame= training_data, \n",
    "    x = 'YearBuilt',\n",
    "    title= 'Box plot YearBuilt',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e4266",
   "metadata": {},
   "source": [
    "There are few houses built before 1885.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 1stFlrSF\n",
    "px.histogram(\n",
    "    data_frame= training_data,\n",
    "    x = 'YearBuilt',\n",
    "    title= 'Distribution of original construction date',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07229bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "px.scatter(\n",
    "    data_frame= training_data,\n",
    "    x = 'YearBuilt',\n",
    "    y = 'SalePrice',\n",
    "    color= 'OverallQual'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91fb06",
   "metadata": {},
   "source": [
    "In this plot, new house have a overall quality more than the older. \n",
    "\n",
    "But from that, the sale price is weakly affected by year built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8163487",
   "metadata": {},
   "source": [
    "## Sale price "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33dad4",
   "metadata": {},
   "source": [
    "### Draw a histogram and violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly to visualize the distribution of SalePrice\n",
    "px.histogram(data_frame= training_data, x= 'SalePrice', title='Distribution of SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the violin plot for SalePrice\n",
    "px.violin(training_data, \n",
    "        y='SalePrice',\n",
    "        box=True, points='all', \n",
    "        title='Distribution of SalePrice', \n",
    "        width=800,\n",
    "height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and kurtosis\n",
    "print(f\"Skewness of SalePrice: {training_data['SalePrice'].skew()}\")\n",
    "print(f\"Kurtosis of SalePrice: {training_data['SalePrice'].kurtosis()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0cb88",
   "metadata": {},
   "source": [
    "### Draw distribution analysis and Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb10e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_pdf(feature_name, data_frame):\n",
    "    # Create histogram with normal probability density function overlay using seaborn\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create histogram with density and KDE\n",
    "    sns.histplot(data_frame[feature_name], kde=True, stat='density', alpha=0.7)\n",
    "    \n",
    "    # Fit normal distribution and overlay\n",
    "    mu, std = norm.fit(data_frame[feature_name].dropna())\n",
    "    x = np.linspace(data_frame[feature_name].min(), data_frame[feature_name].max(), 100)\n",
    "    plt.plot(x, norm.pdf(x, mu, std), 'r-', linewidth=2, \n",
    "             label=f'Normal Fit (μ={mu:.2f}, σ={std:.2f})')\n",
    "    \n",
    "    plt.title(f'Histogram of {feature_name} with Normal Fit')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_qq_plot(data_frame, column_name, title=\"Q-Q Plot\"):\n",
    "    # Create a Q-Q plot to test for normality of data using scipy and matplotlib\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create Q-Q plot\n",
    "    stats.probplot(data_frame[column_name].dropna(), dist=\"norm\", plot=plt)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def apply_log_transform(feature_name, data_frame):\n",
    "    # Apply log1p transformation to make distribution more normal\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_copy = data_frame.copy()\n",
    "    df_copy[feature_name] = np.log1p(data_frame[feature_name])\n",
    "    return df_copy\n",
    "\n",
    "def analyze_distribution(data_frame, feature_name, apply_log=False):    \n",
    "    # Complete distribution analysis with before/after log transformation\n",
    "    print(f\"=== Distribution Analysis for {feature_name} ===\")\n",
    "    \n",
    "    # Original distribution\n",
    "    print(\"\\n1. Original Distribution:\")\n",
    "    \n",
    "    # Histogram with normal fit\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Subplot 1: Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data_frame[feature_name], kde=True, stat='density', alpha=0.7)\n",
    "    mu, std = norm.fit(data_frame[feature_name].dropna())\n",
    "    x = np.linspace(data_frame[feature_name].min(), data_frame[feature_name].max(), 100)\n",
    "    plt.plot(x, norm.pdf(x, mu, std), 'r-', linewidth=2, \n",
    "             label=f'Normal Fit (μ={mu:.2f}, σ={std:.2f})')\n",
    "    plt.title(f'Original {feature_name} Distribution')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Subplot 2: Q-Q Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(data_frame[feature_name].dropna(), dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot: Original {feature_name}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if apply_log:\n",
    "        # Apply log transformation\n",
    "        df_transformed = apply_log_transform(feature_name, data_frame)\n",
    "        \n",
    "        print(f\"\\n2. After Log Transformation:\")\n",
    "        \n",
    "        # Log-transformed distribution plots\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Subplot 1: Log-transformed histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df_transformed[feature_name], kde=True, stat='density', alpha=0.7)\n",
    "        mu_log, std_log = norm.fit(df_transformed[feature_name].dropna())\n",
    "        x_log = np.linspace(df_transformed[feature_name].min(), df_transformed[feature_name].max(), 100)\n",
    "        plt.plot(x_log, norm.pdf(x_log, mu_log, std_log), 'r-', linewidth=2,\n",
    "                 label=f'Normal Fit (μ={mu_log:.2f}, σ={std_log:.2f})')\n",
    "        plt.title(f'Log-transformed {feature_name} Distribution')\n",
    "        plt.xlabel(f'log1p({feature_name})')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Subplot 2: Log-transformed Q-Q Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        stats.probplot(df_transformed[feature_name].dropna(), dist=\"norm\", plot=plt)\n",
    "        plt.title(f'Q-Q Plot: Log-transformed {feature_name}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return df_transformed\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_log = ['SalePrice', 'LotArea', '1stFlrSF', 'GrLivArea', 'TotalBsmtSF']\n",
    "\n",
    "for col in cols_to_log:\n",
    "    training_data = analyze_distribution(training_data, col, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aaf1ab",
   "metadata": {},
   "source": [
    "### Draw boxplots of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986db553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_boxplots(df, categorical_columns, target_col='SalePrice', cols=2):\n",
    "    # Create boxplots for categorical variables vs target variable using Plotly subplots\n",
    "    \n",
    "    # Calculate number of rows needed\n",
    "    n_vars = len(categorical_columns)\n",
    "    rows = (n_vars + cols - 1) // cols  # Ceiling division\n",
    "    \n",
    "    # Create subplot titles\n",
    "    subplot_titles = categorical_columns\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=rows, \n",
    "        cols=cols,\n",
    "        subplot_titles=subplot_titles,\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    # Color palette (similar to tab10)\n",
    "    colors = px.colors.qualitative.Set1\n",
    "    \n",
    "    for i, var in enumerate(categorical_columns):\n",
    "        row = i // cols + 1\n",
    "        col = i % cols + 1\n",
    "        \n",
    "        # Get unique categories and sort them\n",
    "        categories = sorted(df[var].dropna().unique())\n",
    "        \n",
    "        # Create boxplot for each category\n",
    "        for j, category in enumerate(categories):\n",
    "            data_subset = df[df[var] == category][target_col].dropna()\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=data_subset,\n",
    "                    name=str(category),\n",
    "                    boxpoints='outliers',\n",
    "                    marker_color=colors[j % len(colors)],\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        # Update x-axis for this subplot\n",
    "        fig.update_xaxes(\n",
    "            title_text=var,\n",
    "            tickangle=45,\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Update y-axis for this subplot\n",
    "        fig.update_yaxes(\n",
    "            title_text=target_col if col == 1 else \"\",\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update overall layout\n",
    "    fig.update_layout(\n",
    "        height=400 * rows,\n",
    "        width=1200,\n",
    "        title_text=f\"Boxplots of {target_col} by Categorical Variables\",\n",
    "        title_x=0.5,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "def single_boxplot_plotly(df, x_col, y_col, title=None):\n",
    "    # Create a single boxplot using Plotly\n",
    "    # Method 3: Single boxplot\n",
    "    # fig3 = single_boxplot_plotly(df, 'Neighborhood', 'SalePrice')\n",
    "    fig = px.box(\n",
    "        df, \n",
    "        x=x_col, \n",
    "        y=y_col,\n",
    "        color=x_col,\n",
    "        title=title or f\"{y_col} by {x_col}\"\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        width=800,\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fa830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical column names\n",
    "categorical_cols = object_df.columns.tolist()\n",
    "print(f\"Name of categorical columns: {categorical_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1cad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the categorical boxplots\n",
    "fig1 = create_categorical_boxplots(training_data, categorical_cols, 'SalePrice', cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f0659",
   "metadata": {},
   "source": [
    "The boxplots show that some categories, like Zoning, Neighborhood, and Exterior quality, have a strong effect on house prices. For example, certain neighborhoods and better exterior quality are linked to higher prices.\n",
    "\n",
    "Features like central air also tend to raise prices.\n",
    "\n",
    "Some variables, such as Street type and Utilities, do not make much difference in price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412d892",
   "metadata": {},
   "source": [
    "### Draw median bar plot a numerical columms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b82ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values of numerical columns \n",
    "\n",
    "for i in non_object_cols:\n",
    "    print(f\"Number of unique value of {i}: {len(training_data[i].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "\n",
    "threshold = 15\n",
    "discrete_features = [\n",
    "    col for col in non_object_cols\n",
    "    if training_data[col].nunique() <= threshold and col != 'SalePrice'\n",
    "]\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(discrete_features) / n_cols)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n_rows, cols=n_cols,\n",
    "    subplot_titles=discrete_features\n",
    ")\n",
    "\n",
    "# Chuẩn bị dữ liệu median cho từng feature\n",
    "grouped_data = {\n",
    "    feature: training_data.groupby(feature)['SalePrice'].median().reset_index()\n",
    "    for feature in discrete_features\n",
    "}\n",
    "\n",
    "for i, (feature, grouped) in enumerate(grouped_data.items()):\n",
    "    r, c = divmod(i, n_cols)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=grouped[feature],\n",
    "            y=grouped['SalePrice'],\n",
    "            marker_color=grouped['SalePrice'],\n",
    "            marker_colorscale='Viridis',\n",
    "            name=feature\n",
    "        ),\n",
    "        row=r+1, col=c+1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=feature, row=r+1, col=c+1)\n",
    "    fig.update_yaxes(title_text=\"Median SalePrice\", row=r+1, col=c+1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=350 * n_rows,\n",
    "    width=1400,\n",
    "    title_text=\"Median SalePrice by Discrete Numerical Features\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf11e0",
   "metadata": {},
   "source": [
    "1. **OverallQual (Overall Quality):**\n",
    "\n",
    "   * The most influential feature on house prices.\n",
    "   * Houses with high-quality ratings (9–10) have significantly higher median sale prices compared to those with low ratings (1–3), showing a strong positive linear relationship.\n",
    "\n",
    "2. **OverallCond (Overall Condition):**\n",
    "\n",
    "   * Sale prices remain relatively stable across most condition levels.\n",
    "   * Only at the highest condition levels (8–9) do prices slightly increase, suggesting condition is less impactful than quality.\n",
    "\n",
    "3. **BsmtFullBath and BsmtHalfBath (Basement Bathrooms):**\n",
    "\n",
    "   * Having additional full or half bathrooms in the basement increases sale prices.\n",
    "   * The effect is moderate compared to stronger factors like quality or garage size.\n",
    "\n",
    "4. **FullBath and HalfBath (Main Bathrooms):**\n",
    "\n",
    "   * Important contributors to pricing: more full bathrooms strongly correlate with higher prices.\n",
    "   * Adding a half bathroom also raises value, but to a lesser extent than full bathrooms.\n",
    "\n",
    "5. **BedroomAbvGr (Bedrooms) and KitchenAbvGr (Kitchens):**\n",
    "\n",
    "   * The number of bedrooms has little impact on sale price; beyond a certain point, extra bedrooms do not add significant value.\n",
    "   * Most houses have a single kitchen; having multiple kitchens does not increase prices and may even be linked to lower valuations.\n",
    "\n",
    "6. **TotRmsAbvGrd (Total Rooms Above Ground):**\n",
    "\n",
    "   * Shows a positive correlation with sale price: houses with more rooms usually have larger floor areas and higher prices.\n",
    "\n",
    "7. **Fireplaces:**\n",
    "\n",
    "   * More fireplaces are associated with higher prices, reflecting added comfort and luxury features.\n",
    "\n",
    "8. **GarageCars (Garage Capacity):**\n",
    "\n",
    "   * One of the strongest predictors of price.\n",
    "   * Homes with 3–4 garage spaces have substantially higher median sale prices than those with just one.\n",
    "\n",
    "9. **PoolArea:**\n",
    "\n",
    "   * Pools are rare, but when present, they significantly increase sale prices.\n",
    "   * This feature contains outliers and should be treated carefully during modeling.\n",
    "\n",
    "10. **MoSold (Month Sold) and YrSold (Year Sold):**\n",
    "\n",
    "    * The month of sale has negligible impact on pricing.\n",
    "    * The year of sale introduces only minor variations (e.g., slightly higher prices in 2009), not a decisive factor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
